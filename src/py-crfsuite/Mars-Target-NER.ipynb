{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Target Encyclopedia  - NER\n",
    "Thamme Gowda (Thamme.Gowda@jpl.nasa.gov)\n",
    "\n",
    "Named Entity Recognition / Sequence Tagging\n",
    "This notebook contains NER tagging using CRF suite\n",
    "\n",
    "\n",
    "### Notes:\n",
    " + Use python3, Reason: we need unicode strings, which is default in python3\n",
    " + install Python-crfsuite\n",
    " + Start CoreNLP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.1\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from codecs import open as copen\n",
    "from collections import defaultdict as ddict\n",
    "from csv import DictWriter\n",
    "import sys\n",
    "from copy import copy\n",
    "import time\n",
    "from pprint import pprint\n",
    "import re\n",
    "\n",
    "import os, glob\n",
    "import pickle\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#accept_labels = set(['Element', 'Mineral', 'Target', 'Material', 'Locality', 'Site'])\n",
    "accept_labels = set(['Target', 'Mineral', 'Element'])\n",
    "\n",
    "class BratToCRFSuitFeaturizer(object):\n",
    "    def __init__(self, corenlp_url='http://localhost:9000', iob=False):\n",
    "        '''\n",
    "        Create Converter for converting brat annotations to Core NLP NER CRF\n",
    "        classifier training data.\n",
    "        @param corenlp_url: URL to corenlp server.\n",
    "                To start the server checkout: http://stanfordnlp.github.io/CoreNLP/corenlp-server.html#getting-started\n",
    "        @param iob: set 'True' for IOB encoding\n",
    "        '''\n",
    "        self.corenlp = StanfordCoreNLP(corenlp_url)\n",
    "        self.iob = iob\n",
    "\n",
    "    def convert(self, text_file, ann_file):\n",
    "        text, tree = self.parse(text_file, ann_file)\n",
    "        props = { 'annotators': 'tokenize,ssplit,lemma,pos', 'outputFormat': 'json'}\n",
    "        if text[0].isspace():\n",
    "            text = '.' + text[1:]\n",
    "            # Reason: some tools trim/strip off the white spaces\n",
    "            # which will mismatch the character offsets\n",
    "        output = self.corenlp.annotate(text, properties=props)\n",
    "        records = []\n",
    "        for sentence in output['sentences']:\n",
    "            sent_features = []\n",
    "            continue_ann, continue_ann_en = None, None\n",
    "            for tok in sentence['tokens']:\n",
    "                begin, tok_end = tok['characterOffsetBegin'], tok['characterOffsetEnd']\n",
    "                label = 'O'\n",
    "                if begin in tree:\n",
    "                    node = tree[begin]\n",
    "                    if len(node) > 1:\n",
    "                        print(\"WARN: multiple starts at \", begin, node)\n",
    "                        if tok_end in node:\n",
    "                            node = {tok_end: node[tok_end]} # picking one\n",
    "                            print(\"Chose:\", node)\n",
    "\n",
    "                    ann_end, labels = list(node.items())[0]\n",
    "                    if not len(labels) == 1:\n",
    "                        print(\"WARN: Duplicate labels for token: %s, label:%s.\\\n",
    "                              Using the first one!\" % (tok['word'], str(labels)))\n",
    "                    if accept_labels is not None and labels[0] in accept_labels:\n",
    "                        label = labels[0]\n",
    "\n",
    "                    if tok_end == ann_end: # annotation ends where token ends\n",
    "                        continue_ann = None\n",
    "                    elif tok_end < ann_end and label != 'O':\n",
    "                        #print(\"Continue for the next %d chars\" % (ann_end - tok_end))\n",
    "                        continue_ann = label\n",
    "                        continue_ann_end = ann_end \n",
    "                    if label != 'O' and self.iob:\n",
    "                        label = \"B-\" + label\n",
    "                elif continue_ann is not None and tok_end <= continue_ann_end:\n",
    "                    #print(\"Continuing the annotation %s, %d:%d %d]\" % \n",
    "                    #(continue_ann, begin, tok_end, continue_ann_end))\n",
    "                    label = continue_ann            # previous label is this label\n",
    "                    if continue_ann_end == tok_end: # continuation ends here\n",
    "                        #print(\"End\")\n",
    "                        continue_ann = None\n",
    "                    if self.iob:\n",
    "                        label = \"I-\" + label\n",
    "                sent_features.append([tok['word'], tok['lemma'], tok['pos'], label])\n",
    "            yield sent_features\n",
    "\n",
    "\n",
    "    def parse(self, txt_file, ann_file):\n",
    "        with copen(ann_file, 'r', encoding='utf-8') as ann_file:\n",
    "            with copen(txt_file, 'r', encoding='utf-8') as text_file:\n",
    "                texts = text_file.read()\n",
    "            anns = map(lambda x: x.strip().split('\\t'), ann_file)\n",
    "            anns = filter(lambda x: len(x) > 2, anns)\n",
    "            # FIXME: ignoring the annotatiosn which are complex\n",
    "\n",
    "            anns = filter(lambda x: ';' not in x[1], anns)\n",
    "            # FIXME: some annotations' spread have been split into many, separated by ; ignoring them\n",
    "\n",
    "            def __parse_ann(ann):\n",
    "                spec = ann[1].split()\n",
    "                name = spec[0]\n",
    "                markers = list(map(lambda x: int(x), spec[1:]))\n",
    "                #t = ' '.join([texts[begin:end] for begin,end in zip(markers[::2], markers[1::2])])\n",
    "                t = texts[markers[0]:markers[1]]\n",
    "                if not t == ann[2]:\n",
    "                    print(\"Error: Annotation mis-match, file=%s, ann=%s\" % (txt_file, str(ann)))\n",
    "                    return None\n",
    "                return (name, markers, t)\n",
    "            anns = map(__parse_ann, anns) # format\n",
    "            anns = filter(lambda x: x, anns) # skip None\n",
    "\n",
    "            # building a tree index for easy accessing\n",
    "            tree = {}\n",
    "            for entity_type, pos, name in anns:\n",
    "                if entity_type not in accept_labels:\n",
    "                    continue\n",
    "                begin, end = pos[0], pos[1]\n",
    "                if begin not in tree:\n",
    "                    tree[begin] = {}\n",
    "                node = tree[begin]\n",
    "                if end not in node:\n",
    "                    node[end] = []\n",
    "                node[end].append(entity_type)\n",
    "\n",
    "            # Re-read file in without decoding it\n",
    "            text_file = copen(txt_file, 'r', encoding='utf-8')\n",
    "            texts = text_file.read()\n",
    "            text_file.close()\n",
    "            return texts, tree\n",
    "\n",
    "def scan_dir(dir_name):\n",
    "    items = glob.glob(dir_name + \"/*.ann\")\n",
    "    items = map(lambda f: (f, f.replace(\".ann\", \".txt\")), items)\n",
    "    return items\n",
    "\n",
    "def preprocess_all(list_file, out_file):\n",
    "    featzr = BratToCRFSuitFeaturizer(iob=True)\n",
    "    tokenized = []\n",
    "    with open(list_file) as f:\n",
    "        examples = map(lambda l:l.strip().split(','), f.readlines())\n",
    "    for txt_file, ann_file in examples:\n",
    "        sents = featzr.convert(txt_file, ann_file)\n",
    "        tokenized.append(list(sents))\n",
    "\n",
    "    pickle.dump(tokenized, open(out_file, 'wb'))\n",
    "    print(\"Dumped %d docs to %s\" % (len(tokenized), out_file))\n",
    "\n",
    "#######################\n",
    "# Evaluates the model\n",
    "def evaluate(tagger, corpus_file):\n",
    "    \n",
    "    corpus = pickle.load(open(corpus_file, 'rb'))\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for doc in corpus:\n",
    "        seq = merge_sequences(doc)\n",
    "        truth = seq2labels(seq)\n",
    "        preds = tagger.tag(seq2features(seq))\n",
    "        assert len(truth) == len(preds)\n",
    "        y_true.extend(truth)\n",
    "        y_pred.extend(preds)    \n",
    "    assert len(y_true) == len(y_pred)\n",
    "    table = ddict(lambda: ddict(int)) \n",
    "    for truth, pred in zip(y_true, y_pred):\n",
    "        table[truth][pred] += 1\n",
    "        table[truth]['total'] += 1\n",
    "        table['total'][pred] += 1\n",
    "        table['total']['total'] += 1\n",
    "    keys = []\n",
    "    for label in accept_labels:\n",
    "        keys.append('B-%s' % label)\n",
    "        keys.append('I-%s' % label)\n",
    "    col_keys = copy(keys)\n",
    "    precision, recall = {}, {}\n",
    "    for k in set(keys):\n",
    "        tot_preds = table['total'][k]\n",
    "        tot_truth = table[k]['total']\n",
    "        table['Precision'][k] = \"%.4f\" % (float(table[k][k]) / tot_preds) if tot_preds else 0 \n",
    "        table['Recall'][k] = \"%.4f\" % (float(table[k][k]) / tot_truth) if tot_truth else 0 \n",
    "    col_keys.extend(['O', 'total'])\n",
    "    keys.extend(['', 'Precision', 'Recall', '', 'O', 'total'])\n",
    "    return table, keys, col_keys\n",
    "\n",
    "\n",
    "def printtable(table, row_keys, col_keys, delim=','):\n",
    "    \"\"\"\n",
    "    print table in CSV format which is meant to be copy pasted to Excel sheet \n",
    "    \"\"\"\n",
    "    f = sys.stdout\n",
    "    out = DictWriter(f, delimiter=delim, restval=0, fieldnames=keys)\n",
    "    f.write(\"%s%s\" % (\"***\", delim))\n",
    "    out.writeheader()\n",
    "    for k in row_keys:\n",
    "        if not k.strip():\n",
    "            f.write(\"\\n\")\n",
    "            continue\n",
    "        f.write(\"%s%s\" % (k, delim))\n",
    "        out.writerow(table[k])\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse and store the corpus\n",
    "\n",
    "In this step, we pass the text through CoreNLP pipeline, tokenize and POS tag them. \n",
    "In addition, we lookup the annotations file and match the target annotations with the token. \n",
    "\n",
    "Since this step is expensive, we store the results in pickle file, so that we can later load and resume our analysis for feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_dir = \"/Users/thammegr/work/mte/data/newcorpus/workspace\"\n",
    "train_list = p_dir + \"/train_62r15_685k14_384k15.list\"\n",
    "dev_list= p_dir + \"/development.list\"\n",
    "test_list = p_dir + \"/test.list\"\n",
    "\n",
    "train_corpus_file = 'mte-corpus-train.pickle'\n",
    "preprocess_all(train_list, train_corpus_file)\n",
    "\n",
    "# Test and Development set\n",
    "dev_corpus_file = 'mte-corpus-dev.pickle'\n",
    "preprocess_all(dev_list, dev_corpus_file)\n",
    "test_corpus_file = 'mte-corpus-test.pickle'\n",
    "preprocess_all(test_list, test_corpus_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the corpus\n",
    "Here we load the corpus from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hollow', 'hollow', 'JJ', 'O'],\n",
       " ['spherical', 'spherical', 'JJ', 'O'],\n",
       " ['feature', 'feature', 'NN', 'O'],\n",
       " ['observed', 'observe', 'VBN', 'O'],\n",
       " ['on', 'on', 'IN', 'O'],\n",
       " ['sol', 'sol', 'NN', 'O'],\n",
       " ['122', '122', 'CD', 'O'],\n",
       " ['in', 'in', 'IN', 'O'],\n",
       " ['the', 'the', 'DT', 'O'],\n",
       " ['Yellowknife', 'Yellowknife', 'NNP', 'O'],\n",
       " ['Bay', 'Bay', 'NNP', 'O'],\n",
       " ['area', 'area', 'NN', 'O'],\n",
       " ['.', '.', '.', 'O']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_file = 'mte-corpus-train.pickle'\n",
    "corpus = pickle.load(open(corpus_file, 'rb'))\n",
    "corpus[0][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we start playing with the features of CRF Suite to build a sequence tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample features:\n",
      "['hollow', 'hollow', 'JJ', 'O']\n",
      "['.', '.', '.', 'O']\n",
      "['|', '|', '|', 'O']\n",
      "['No', 'no', 'DT', 'O']\n",
      "['such', 'such', 'JJ', 'O']\n",
      "['features', 'feature', 'NNS', 'O']\n",
      "['were', 'be', 'VBD', 'O']\n",
      "['observed', 'observe', 'VBN', 'O']\n",
      "['across', 'across', 'IN', 'O']\n",
      "['Bradbury', 'Bradbury', 'NNP', 'O']\n",
      "['Rise', 'rise', 'NN', 'O']\n",
      "[',', ',', ',', 'O']\n",
      "-1word.bias\n",
      "-1word.genpos=NN\n",
      "-1word[-1:]=s\n",
      "-1word[-2:]=es\n",
      "-1word[-3:]=res\n",
      "-1word.islower=True\n",
      "-1word.isupper=False\n",
      "-1word.istitle=False\n",
      "-1word.shape=cvcvcvc\n",
      "0word.bias\n",
      "0word.genpos=VB\n",
      "0word[-1:]=e\n",
      "0word[-2:]=re\n",
      "0word[-3:]=ere\n",
      "0word.islower=True\n",
      "0word.isupper=False\n",
      "0word.istitle=False\n",
      "0word.shape=cvcv\n",
      "1word.bias\n",
      "1word.genpos=VB\n",
      "1word[-1:]=d\n",
      "1word[-2:]=ed\n",
      "1word[-3:]=ved\n",
      "1word.islower=True\n",
      "1word.isupper=False\n",
      "1word.istitle=False\n",
      "1word.shape=vcvcvc\n",
      "['feature.minfreq',\n",
      " 'feature.possible_states',\n",
      " 'feature.possible_transitions',\n",
      " 'c1',\n",
      " 'c2',\n",
      " 'max_iterations',\n",
      " 'num_memories',\n",
      " 'epsilon',\n",
      " 'period',\n",
      " 'delta',\n",
      " 'linesearch',\n",
      " 'max_linesearch']\n",
      "{'POS': False,\n",
      " 'bias': True,\n",
      " 'context': [-1, 0, 1],\n",
      " 'gen_POS': True,\n",
      " 'is_lower': True,\n",
      " 'is_title': True,\n",
      " 'is_upper': True,\n",
      " 'max_suffix_chars': 3,\n",
      " 'wordshape': 'sound_case'}\n",
      "Training Time: 106.344s\n",
      "\n",
      "Evaluating on Development Set\n",
      "\n",
      "***,B-Mineral,I-Mineral,B-Target,I-Target,B-Element,I-Element,O,total\n",
      "B-Mineral,131,0,0,0,1,0,108,240\n",
      "I-Mineral,0,0,0,0,0,0,0,0\n",
      "B-Target,0,0,25,0,0,0,122,147\n",
      "I-Target,0,0,0,6,0,0,8,14\n",
      "B-Element,2,0,0,0,310,0,63,375\n",
      "I-Element,0,0,0,0,0,0,0,0\n",
      "\n",
      "Precision,0.8506,0,0.8929,0.8571,0.8883,0,0,0\n",
      "Recall,0.5458,0,0.1701,0.4286,0.8267,0,0,0\n",
      "\n",
      "O,21,0,3,1,38,0,34131,34194\n",
      "total,154,0,28,7,349,0,34432,34970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "config = {\n",
    "    'POS': False,\n",
    "    'gen_POS': True, # generalize POS\n",
    "    'bias': True,\n",
    "    'max_suffix_chars': 3,\n",
    "    'is_lower': True,\n",
    "    'is_upper': True,\n",
    "    'is_title': True,\n",
    "    'wordshape': 'sound_case',\n",
    "    'context': list(range(-1, 2))\n",
    "}\n",
    "\n",
    "def get_wordshape_general(word):\n",
    "    \"\"\"\n",
    "    Makes shape of the word based on upper case, lowercase or digit\n",
    "    \"\"\"\n",
    "    # Note : the order of replacement matters, digits should be at the last\n",
    "    return re.sub(\"[0-9]\", 'd', \n",
    "                  re.sub(\"[A-Z]\", 'X',\n",
    "                         re.sub(\"[a-z]\", 'x', word)))\n",
    "\n",
    "def get_wordshape_sound(word):\n",
    "    \"\"\"\n",
    "    Makes shape of word based on the vowel or consonenet sound\n",
    "    \"\"\"\n",
    "    # Note : the order of replacement matters, c, v, d in order\n",
    "    word = re.sub(\"[bcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXYZ]\", 'c', word) # consonents\n",
    "    word = re.sub(\"[AEIOUaeiou]\", 'v', word) # vowels\n",
    "    word = re.sub(\"[0-9]\", 'd', word) # digits\n",
    "    return word\n",
    "\n",
    "def get_wordshape_sound_case(word):\n",
    "    \"\"\"\n",
    "    Makes shape of word based on the vowel or consonenet sound considering case\n",
    "    This one reduces the size by grouping the similar sounds (+ char in regex)\n",
    "    \"\"\"\n",
    "    word = re.sub(\"[bcdfghjklmnpqrstvwxyz]+\", 'c', word) # consonents\n",
    "    word = re.sub(\"[BCDFGHJKLMNPQRSTVWXYZ]+\", 'C', word) # upper consonents\n",
    "    word = re.sub(\"[aeiou]+\", 'v', word) # vowels\n",
    "    word = re.sub(\"[AEIOU]+\", 'V', word) # upper vowels\n",
    "    word = re.sub(\"[+-]?[0-9]+(\\.[0-9]+)?\", 'N', word) # digits\n",
    "    return word\n",
    "\n",
    "def word2features(sent, idx):\n",
    "    word = sent[idx]\n",
    "    words = []\n",
    "    feats = []\n",
    "\n",
    "    # Context\n",
    "    context = set(config.get('context', []))\n",
    "    context.add(0)  # current word\n",
    "    for ctx in sorted(context):\n",
    "        pos = ctx + idx\n",
    "        if pos >= 0 and pos < len(sent):\n",
    "            words.append((str(ctx), sent[pos]))\n",
    "    \n",
    "    if idx == 0:\n",
    "        feats.append('BOS') # begin of sequence\n",
    "    if idx == len(sent) - 1:\n",
    "        feats.append('EOS')\n",
    "    for prefix, word in words:\n",
    "        if config.get('bias'):\n",
    "            feats.append('%sword.bias'% (prefix))\n",
    "        if config.get('POS'):\n",
    "            feats.append('%sword.pos=%s' %(prefix, word[2]))\n",
    "        if config.get('gen_POS'):\n",
    "            feats.append('%sword.genpos=%s' %(prefix, word[2][:2]))\n",
    "        if config.get('max_suffix_chars'):\n",
    "            for i in range(1, config.get('max_suffix_chars', -1) + 1):\n",
    "                if len(word[0]) < i:\n",
    "                    break\n",
    "                feats.append('%sword[-%d:]=%s' % (prefix, i, word[0][-i:]))\n",
    "        if config.get('is_lower'):\n",
    "            feats.append('%sword.islower=%s' % (prefix, word[0].islower()))\n",
    "        if config.get('is_upper'):\n",
    "            feats.append('%sword.isupper=%s' % (prefix, word[0].isupper()))\n",
    "        if config.get('is_title'):\n",
    "            feats.append('%sword.istitle=%s' % (prefix, word[0].istitle()))\n",
    "        if config.get('wordshape'):\n",
    "            shape = config['wordshape'] \n",
    "            if shape == 'general':\n",
    "                shape_val = get_wordshape_general(word[0])\n",
    "            elif shape == 'sound':\n",
    "                shape_val = get_wordshape_sound(word[0])\n",
    "            elif shape == 'sound_case':\n",
    "                shape_val = get_wordshape_sound_case(word[0])\n",
    "            else:\n",
    "                raise Error(\"Word Shape spec unknown '%s'\" % config['wordshape'])\n",
    "            feats.append('%sword.shape=%s' % (prefix, shape_val))\n",
    "    return feats\n",
    "\n",
    "def seq2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def seq2labels(sent):\n",
    "    return [tok[3] for tok in sent]\n",
    "\n",
    "def merge_sequences(doc):\n",
    "    '''\n",
    "    document contains multiple sentences. here all sentences in document are merged to form one large sequence.\n",
    "    '''\n",
    "    res = []\n",
    "    for seq in doc:\n",
    "        res.extend(seq)\n",
    "        res.append(['|', '|', '|', 'O']) # sentence end marker\n",
    "    return res\n",
    "  \n",
    "\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "# Load training examples\n",
    "flag = True\n",
    "for doc in corpus:\n",
    "    seq = merge_sequences(doc)\n",
    "    x_seq = seq2features(seq)\n",
    "    if flag:\n",
    "        p = 403\n",
    "        print(\"Sample features:\")\n",
    "        print(\"\\n\".join(map(str, seq[p-6:p+6])))\n",
    "        print(\"\\n\".join(x_seq[p]))\n",
    "        flag = False\n",
    "    y_seq = seq2labels(seq)\n",
    "    trainer.append(x_seq, y_seq)\n",
    "\n",
    "trainer.set_params({\n",
    "    'c1': 0.5,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})\n",
    "\n",
    "st = time.time()\n",
    "pprint(trainer.params())\n",
    "pprint(config)\n",
    "model_file = 'jpl-mars-target-ner-model.crfsuite'\n",
    "trainer.train(model_file)\n",
    "print(\"Training Time: %.3fs\" % (time.time() - st))\n",
    "\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open(model_file)\n",
    "print(\"\\nEvaluating on Development Set\\n\")\n",
    "dev_corpus_file = 'mte-corpus-dev.pickle'\n",
    "printtable(*evaluate(tagger, dev_corpus_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Using the model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx, Truth, Predicted, Word, Comment \n",
      " 500         O         O       -3 ['Cooperstown', 'Cooperstown', 'NNP', 'O']\n",
      " 501         O         O       -2 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      " 502         O         O       -1 ['-4.62', '-4.62', 'CD', 'O']\n",
      " 503         O B-Element    <ERR> ['N', 'n', 'NN', 'O']\n",
      " 504         O         O        1 [',', ',', ',', 'O']\n",
      " 505         O         O        2 ['137.42', '137.42', 'CD', 'O']\n",
      " 506         O         O        3 ['E', 'e', 'NN', 'O']\n",
      "\n",
      " 550         O         O       -3 ['Kimberley', 'kimberley', 'NN', 'O']\n",
      " 551         O         O       -2 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      " 552         O         O       -1 ['-4.64', '-4.64', 'CD', 'O']\n",
      " 553         O B-Element    <ERR> ['N', 'n', 'NN', 'O']\n",
      " 554         O         O        1 [',', ',', ',', 'O']\n",
      " 555         O         O        2 ['137.4', '137.4', 'CD', 'O']\n",
      " 556         O         O        3 ['E', 'e', 'NN', 'O']\n",
      "\n",
      "1536         O         O       -3 ['.', '.', '.', 'O']\n",
      "1537         O         O       -2 ['|', '|', '|', 'O']\n",
      "1538         O         O       -1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1539         O B-Element    <ERR> ['B', 'b', 'NN', 'O']\n",
      "1540         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "1541         O         O        2 ['Na2O', 'na2o', 'NN', 'O']\n",
      "1542         O         O        3 ['versus', 'versus', 'CC', 'O']\n",
      "\n",
      " 412         O         O       -3 ['using', 'use', 'VBG', 'O']\n",
      " 413         O         O       -2 ['a', 'a', 'DT', 'O']\n",
      " 414         O         O       -1 ['1064-nm', '1064-nm', 'JJ', 'O']\n",
      " 415         O B-Element    <ERR> ['Nd', 'nd', 'NN', 'O']\n",
      " 416         O         O        1 [':', ':', ':', 'O']\n",
      " 417         O         O        2 ['YAG', 'yag', 'NN', 'O']\n",
      " 418         O         O        3 ['q-switched', 'q-switched', 'JJ', 'O']\n",
      "\n",
      " 807         O         O       -3 ['/', '/', ':', 'O']\n",
      " 808         O         O       -2 ['Si', 'Si', 'NNP', 'O']\n",
      " 809         O         O       -1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      " 810         O B-Element    <ERR> ['I', 'I', 'PRP', 'O']\n",
      " 811         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      " 812         O         O        2 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      " 813         O         O        3 ['634', '634', 'CD', 'O']\n",
      "\n",
      " 951         O         O       -3 ['The', 'the', 'DT', 'O']\n",
      " 952         O         O       -2 ['ratio', 'ratio', 'NN', 'O']\n",
      " 953         O         O       -1 ['of', 'of', 'IN', 'O']\n",
      " 954         O B-Element    <ERR> ['Si', 'Si', 'NNP', 'O']\n",
      " 955         O         O        1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      " 956         O         O        2 ['II', 'II', 'NNP', 'O']\n",
      " 957         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "\n",
      " 958         O         O       -3 ['/', '/', ':', 'O']\n",
      " 959         O         O       -2 ['Si', 'Si', 'NNP', 'O']\n",
      " 960         O         O       -1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      " 961         O B-Element    <ERR> ['I', 'I', 'PRP', 'O']\n",
      " 962         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      " 963         O         O        2 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      " 964         O         O        3 ['634', '634', 'CD', 'O']\n",
      "\n",
      "1001         O         O       -3 ['/', '/', ':', 'O']\n",
      "1002         O         O       -2 ['Si', 'Si', 'NNP', 'O']\n",
      "1003         O         O       -1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1004         O B-Element    <ERR> ['I', 'I', 'PRP', 'O']\n",
      "1005         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "1006         O         O        2 ['curve', 'curve', 'NN', 'O']\n",
      "1007         O         O        3 ['for', 'for', 'IN', 'O']\n",
      "\n",
      "1050         O         O       -3 ['.', '.', '.', 'O']\n",
      "1051         O         O       -2 ['|', '|', '|', 'O']\n",
      "1052         O         O       -1 ['Decreasing', 'decrease', 'VBG', 'O']\n",
      "1053         O B-Element    <ERR> ['Si', 'Si', 'NNP', 'O']\n",
      "1054         O         O        1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1055         O         O        2 ['II', 'II', 'NNP', 'O']\n",
      "1056         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "\n",
      "1057         O         O       -3 ['/', '/', ':', 'O']\n",
      "1058         O         O       -2 ['Si', 'Si', 'NNP', 'O']\n",
      "1059         O         O       -1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1060         O B-Element    <ERR> ['I', 'I', 'PRP', 'O']\n",
      "1061         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "1062         O         O        2 ['ratios', 'ratio', 'NNS', 'O']\n",
      "1063         O         O        3 ['toward', 'toward', 'IN', 'O']\n",
      "\n",
      "1068         O         O       -3 ['collection', 'collection', 'NN', 'O']\n",
      "1069         O         O       -2 ['suggest', 'suggest', 'VBP', 'O']\n",
      "1070         O         O       -1 ['that', 'that', 'IN', 'O']\n",
      "1071         O B-Element    <ERR> ['Si', 'Si', 'NNP', 'O']\n",
      "1072         O         O        1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1073         O         O        2 ['II', 'II', 'NNP', 'O']\n",
      "1074         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "\n",
      "1073         O         O       -3 ['II', 'II', 'NNP', 'O']\n",
      "1074         O         O       -2 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "1075         O         O       -1 ['and', 'and', 'CC', 'O']\n",
      "1076         O B-Element    <ERR> ['Si', 'Si', 'NNP', 'O']\n",
      "1077         O         O        1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1078         O B-Element        2 ['I', 'I', 'PRP', 'O']\n",
      "1079         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "\n",
      "1075         O         O       -3 ['and', 'and', 'CC', 'O']\n",
      "1076         O B-Element       -2 ['Si', 'Si', 'NNP', 'O']\n",
      "1077         O         O       -1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1078         O B-Element    <ERR> ['I', 'I', 'PRP', 'O']\n",
      "1079         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "1080         O         O        2 ['have', 'have', 'VBP', 'O']\n",
      "1081         O         O        3 ['different', 'different', 'JJ', 'O']\n",
      "\n",
      "1086         O         O       -3 ['plasma', 'plasma', 'NN', 'O']\n",
      "1087         O         O       -2 [',', ',', ',', 'O']\n",
      "1088         O         O       -1 ['and', 'and', 'CC', 'O']\n",
      "1089         O B-Element    <ERR> ['Si', 'Si', 'NNP', 'O']\n",
      "1090         O         O        1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1091         O B-Element        2 ['I', 'I', 'PRP', 'O']\n",
      "1092         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "\n",
      "1088         O         O       -3 ['and', 'and', 'CC', 'O']\n",
      "1089         O B-Element       -2 ['Si', 'Si', 'NNP', 'O']\n",
      "1090         O         O       -1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1091         O B-Element    <ERR> ['I', 'I', 'PRP', 'O']\n",
      "1092         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "1093         O         O        2 ['is', 'be', 'VBZ', 'O']\n",
      "1094         O         O        3 ['preferentially', 'preferentially', 'RB', 'O']\n",
      "\n",
      "1111         O         O       -3 ['who', 'who', 'WP', 'O']\n",
      "1112         O         O       -2 ['found', 'find', 'VBD', 'O']\n",
      "1113         O         O       -1 ['that', 'that', 'IN', 'O']\n",
      "1114         O B-Element    <ERR> ['Al', 'Al', 'NNP', 'O']\n",
      "1115         O         O        1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1116         O         O        2 ['II', 'II', 'NNP', 'O']\n",
      "1117         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "\n",
      "1118         O         O       -3 ['propagates', 'propagate', 'VBZ', 'O']\n",
      "1119         O         O       -2 ['vertically', 'vertically', 'RB', 'O']\n",
      "1120         O         O       -1 ['while', 'while', 'IN', 'O']\n",
      "1121         O B-Element    <ERR> ['Al', 'Al', 'NNP', 'O']\n",
      "1122         O         O        1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1123         O B-Element        2 ['I', 'I', 'PRP', 'O']\n",
      "1124         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "\n",
      "1120         O         O       -3 ['while', 'while', 'IN', 'O']\n",
      "1121         O B-Element       -2 ['Al', 'Al', 'NNP', 'O']\n",
      "1122         O         O       -1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1123         O B-Element    <ERR> ['I', 'I', 'PRP', 'O']\n",
      "1124         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "1125         O         O        2 ['propagates', 'propagate', 'VBZ', 'O']\n",
      "1126         O         O        3 ['horizontally', 'horizontally', 'RB', 'O']\n",
      "\n",
      "1133         O         O       -3 [',', ',', ',', 'O']\n",
      "1134 B-Element B-Element       -2 ['Si', 'Si', 'NNP', 'B-Element']\n",
      "1135         O         O       -1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1136         O B-Element    <ERR> ['I', 'I', 'PRP', 'O']\n",
      "1137         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "1138         O         O        2 ['could', 'could', 'MD', 'O']\n",
      "1139         O         O        3 ['be', 'be', 'VB', 'O']\n",
      "\n",
      "1185         O         O       -3 ['1', '1', 'LS', 'O']\n",
      "1186         O         O       -2 ['-RSB-', '-rsb-', '-RRB-', 'O']\n",
      "1187         O         O       -1 ['Maurice', 'Maurice', 'NNP', 'O']\n",
      "1188         O B-Element    <ERR> ['S.', 'S.', 'NNP', 'O']\n",
      "1189         O         O        1 [',', ',', ',', 'O']\n",
      "1190         O         O        2 ['et', 'et', 'FW', 'O']\n",
      "1191         O         O        3 ['al.', 'al.', 'FW', 'O']\n",
      "\n",
      " 157         O         O       -3 ['8U', '8u', 'NN', 'O']\n",
      " 158         O         O       -2 ['.', '.', '.', 'O']\n",
      " 159         O         O       -1 ['|', '|', '|', 'O']\n",
      " 160         O B-Element    <ERR> ['Copenhagen', 'Copenhagen', 'NNP', 'O']\n",
      " 161         O         O        1 [',', ',', ',', 'O']\n",
      " 162         O         O        2 ['9UNM', '9unm', 'NN', 'O']\n",
      " 163         O         O        3 [',', ',', ',', 'O']\n",
      "\n",
      "1707         O         O       -3 ['-RSB-', '-rsb-', '-RRB-', 'O']\n",
      "1708         O         O       -2 ['Mielke', 'Mielke', 'NNP', 'O']\n",
      "1709         O         O       -1 [',', ',', ',', 'O']\n",
      "1710         O B-Element    <ERR> ['P.', 'P.', 'NNP', 'O']\n",
      "1711         O         O        1 [',', ',', ',', 'O']\n",
      "1712         O         O        2 ['&', '&', 'CC', 'O']\n",
      "1713         O         O        3 ['Winkler', 'Winkler', 'NNP', 'O']\n",
      "\n",
      "1339         O         O       -3 ['of', 'of', 'IN', 'O']\n",
      "1340         O         O       -2 ['the', 'the', 'DT', 'O']\n",
      "1341         O         O       -1 ['enriched', 'enriched', 'JJ', 'O']\n",
      "1342         O B-Element    <ERR> ['Sr-Rb-Ba', 'sr-rb-ba', 'NN', 'O']\n",
      "1343         O         O        1 ['targets', 'target', 'NNS', 'O']\n",
      "1344         O         O        2 ['are', 'be', 'VBP', 'O']\n",
      "1345         O         O        3 ['located', 'located', 'JJ', 'O']\n",
      "\n",
      "1638         O         O       -3 ['between', 'between', 'IN', 'O']\n",
      "1639 B-Element B-Element       -2 ['Li', 'Li', 'NNP', 'B-Element']\n",
      "1640         O         O       -1 ['and', 'and', 'CC', 'O']\n",
      "1641         O B-Element    <ERR> ['Fe-Mn', 'Fe-Mn', 'NNP', 'O']\n",
      "1642         O         O        1 ['is', 'be', 'VBZ', 'O']\n",
      "1643         O         O        2 ['often', 'often', 'RB', 'O']\n",
      "1644         O         O        3 ['observed', 'observe', 'VBN', 'O']\n",
      "\n",
      "1996         O         O       -3 ['-RSB-', '-rsb-', '-RRB-', 'O']\n",
      "1997         O         O       -2 ['Mielke', 'Mielke', 'NNP', 'O']\n",
      "1998         O         O       -1 [',', ',', ',', 'O']\n",
      "1999         O B-Element    <ERR> ['P.', 'P.', 'NNP', 'O']\n",
      "2000         O         O        1 [',', ',', ',', 'O']\n",
      "2001         O         O        2 ['&', '&', 'CC', 'O']\n",
      "2002         O         O        3 ['Winkler', 'Winkler', 'NNP', 'O']\n",
      "\n",
      "  26         O         O       -3 ['T.', 'T.', 'NNP', 'O']\n",
      "  27         O         O       -2 ['Dequaire1', 'Dequaire1', 'NNP', 'O']\n",
      "  28         O         O       -1 [',', ',', ',', 'O']\n",
      "  29         O B-Element    <ERR> ['P', 'p', 'NN', 'O']\n",
      "  30         O         O        1 [',', ',', ',', 'O']\n",
      "  31         O         O        2 ['Y.', 'Y.', 'NNP', 'O']\n",
      "  32         O         O        3 ['Meslin2', 'Meslin2', 'NNP', 'O']\n",
      "\n",
      "  79         O         O       -3 [',', ',', ',', 'O']\n",
      "  80         O         O       -2 ['1LISA', '1lisa', 'NN', 'O']\n",
      "  81         O         O       -1 [',', ',', ',', 'O']\n",
      "  82         O B-Element    <ERR> ['Cr', 'cr', 'NN', 'O']\n",
      "  83         O         O        1 ['teilParis', 'teilparis', 'NN', 'O']\n",
      "  84         O         O        2 [',', ',', ',', 'O']\n",
      "  85         O         O        3 ['France', 'France', 'NNP', 'O']\n",
      "\n",
      "1151 B-Element B-Element       -3 ['nitrogen', 'nitrogen', 'NN', 'B-Element']\n",
      "1152         O         O       -2 ['and', 'and', 'CC', 'O']\n",
      "1153         O         O       -1 ['a', 'a', 'DT', 'O']\n",
      "1154         O B-Element    <ERR> ['C-N', 'c-n', 'NN', 'O']\n",
      "1155         O         O        1 ['vibrational', 'vibrational', 'JJ', 'O']\n",
      "1156         O         O        2 ['molecular', 'molecular', 'JJ', 'O']\n",
      "1157         O         O        3 ['peak', 'peak', 'NN', 'O']\n",
      "\n",
      "1699         O         O       -3 ['reveal', 'reveal', 'VBP', 'O']\n",
      "1700         O         O       -2 ['detections', 'detection', 'NNS', 'O']\n",
      "1701         O         O       -1 ['of', 'of', 'IN', 'O']\n",
      "1702         O B-Element    <ERR> ['N', 'n', 'NN', 'O']\n",
      "1703         O         O        1 [',', ',', ',', 'O']\n",
      "1704         O B-Element        2 ['H', 'h', 'NN', 'O']\n",
      "1705         O         O        3 ['and', 'and', 'CC', 'O']\n",
      "\n",
      "1701         O         O       -3 ['of', 'of', 'IN', 'O']\n",
      "1702         O B-Element       -2 ['N', 'n', 'NN', 'O']\n",
      "1703         O         O       -1 [',', ',', ',', 'O']\n",
      "1704         O B-Element    <ERR> ['H', 'h', 'NN', 'O']\n",
      "1705         O         O        1 ['and', 'and', 'CC', 'O']\n",
      "1706         O         O        2 ['C.', 'C.', 'NNP', 'O']\n",
      "1707         O         O        3 ['1364', '1364', 'CD', 'O']\n",
      "\n",
      "  30         O         O       -3 ['.', '.', '.', 'O']\n",
      "  31         O         O       -2 ['|', '|', '|', 'O']\n",
      "  32         O         O       -1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "  33         O B-Element    <ERR> ['B', 'b', 'NN', 'O']\n",
      "  34         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "  35         O         O        2 ['MAHLI', 'mahli', 'NN', 'O']\n",
      "  36         O         O        3 ['image', 'image', 'NN', 'O']\n",
      "\n",
      " 590         O         O       -3 ['situ', 'situ', 'FW', 'O']\n",
      " 591         O         O       -2 ['measurements', 'measurement', 'NNS', 'O']\n",
      " 592         O         O       -1 ['of', 'of', 'IN', 'O']\n",
      " 593         O B-Element    <ERR> ['Bagnold', 'Bagnold', 'NNP', 'O']\n",
      " 594         O         O        1 ['sand', 'sand', 'NN', 'O']\n",
      " 595         O         O        2 ['composition', 'composition', 'NN', 'O']\n",
      " 596         O         O        3 ['and', 'and', 'CC', 'O']\n",
      "\n",
      " 662         O         O       -3 ['are', 'be', 'VBP', 'O']\n",
      " 663         O         O       -2 ['armored', 'armored', 'JJ', 'O']\n",
      " 664         O         O       -1 ['by', 'by', 'IN', 'O']\n",
      " 665         O B-Element    <ERR> ['medium', 'medium', 'NN', 'O']\n",
      " 666         O         O        1 ['to', 'to', 'TO', 'O']\n",
      " 667         O         O        2 ['coarse', 'coarse', 'JJ', 'O']\n",
      " 668         O         O        3 ['sand', 'sand', 'NN', 'O']\n",
      "\n",
      " 736         O         O       -3 ['APXS', 'apxs', 'NN', 'O']\n",
      " 737         O         O       -2 ['chemistry', 'chemistry', 'NN', 'O']\n",
      " 738         O         O       -1 ['of', 'of', 'IN', 'O']\n",
      " 739         O B-Element    <ERR> ['Bagnold', 'Bagnold', 'NNP', 'O']\n",
      " 740         O         O        1 ['sands', 'sand', 'NNS', 'O']\n",
      " 741         O         O        2 ['and', 'and', 'CC', 'O']\n",
      " 742         O         O        3 ['other', 'other', 'JJ', 'O']\n",
      "\n",
      "1155         O         O       -3 ['absorptions', 'absorption', 'NNS', 'O']\n",
      "1156         O         O       -2 ['indicating', 'indicate', 'VBG', 'O']\n",
      "1157         O         O       -1 ['dominantly', 'dominantly', 'RB', 'O']\n",
      "1158         O B-Element    <ERR> ['Fe', 'Fe', 'NNP', 'O']\n",
      "1159         O         O        1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1160         O         O        2 ['II', 'II', 'NNP', 'O']\n",
      "1161         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "\n",
      "1161         O         O       -3 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "1162         O         O       -2 ['rather', 'rather', 'RB', 'O']\n",
      "1163         O         O       -1 ['than', 'than', 'IN', 'O']\n",
      "1164         O B-Element    <ERR> ['Fe', 'Fe', 'NNP', 'O']\n",
      "1165         O         O        1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1166         O         O        2 ['III', 'III', 'NNP', 'O']\n",
      "1167         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "\n",
      " 145         O         O       -3 ['found', 'find', 'VBN', 'O']\n",
      " 146         O         O       -2 ['in', 'in', 'IN', 'O']\n",
      " 147         O         O       -1 ['the', 'the', 'DT', 'O']\n",
      " 148         O B-Element    <ERR> ['Bradbury', 'Bradbury', 'NNP', 'O']\n",
      " 149         O         O        1 ['formation', 'formation', 'NN', 'O']\n",
      " 150         O         O        2 [',', ',', ',', 'O']\n",
      " 151         O         O        3 ['indicating', 'indicate', 'VBG', 'O']\n",
      "\n",
      "1052         O         O       -3 ['have', 'have', 'VB', 'O']\n",
      "1053         O         O       -2 ['a', 'a', 'DT', 'O']\n",
      "1054         O         O       -1 ['high', 'high', 'JJ', 'O']\n",
      "1055         O B-Element    <ERR> ['Ca', 'ca', 'NN', 'O']\n",
      "1056         O         O        1 ['+', '+', 'CC', 'O']\n",
      "1057         O         O        2 ['Na', 'na', 'NN', 'O']\n",
      "1058         O         O        3 ['+', '+', 'CC', 'O']\n",
      "\n",
      "1056         O         O       -3 ['+', '+', 'CC', 'O']\n",
      "1057         O         O       -2 ['Na', 'na', 'NN', 'O']\n",
      "1058         O         O       -1 ['+', '+', 'CC', 'O']\n",
      "1059         O B-Element    <ERR> ['K', 'k', 'NN', 'O']\n",
      "1060         O         O        1 ['cation', 'cation', 'NN', 'O']\n",
      "1061         O         O        2 ['totals', 'total', 'NNS', 'O']\n",
      "1062         O         O        3 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "\n",
      "1333 B-Mineral B-Mineral       -3 ['andesine', 'andesine', 'NN', 'B-Mineral']\n",
      "1334         O         O       -2 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1335         O         O       -1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1336         O B-Element    <ERR> ['Ca', 'ca', 'NN', 'O']\n",
      "1337         O         O        1 [',', ',', ',', 'O']\n",
      "1338         O B-Element        2 ['Na', 'na', 'NN', 'O']\n",
      "1339         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "\n",
      "1335         O         O       -3 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1336         O B-Element       -2 ['Ca', 'ca', 'NN', 'O']\n",
      "1337         O         O       -1 [',', ',', ',', 'O']\n",
      "1338         O B-Element    <ERR> ['Na', 'na', 'NN', 'O']\n",
      "1339         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "1340         O         O        2 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1341         O B-Element        3 ['Al', 'Al', 'NNP', 'O']\n",
      "\n",
      "1338         O B-Element       -3 ['Na', 'na', 'NN', 'O']\n",
      "1339         O         O       -2 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "1340         O         O       -1 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1341         O B-Element    <ERR> ['Al', 'Al', 'NNP', 'O']\n",
      "1342         O         O        1 [',', ',', ',', 'O']\n",
      "1343         O B-Element        2 ['Si', 'Si', 'NNP', 'O']\n",
      "1344         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "\n",
      "1340         O         O       -3 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      "1341         O B-Element       -2 ['Al', 'Al', 'NNP', 'O']\n",
      "1342         O         O       -1 [',', ',', ',', 'O']\n",
      "1343         O B-Element    <ERR> ['Si', 'Si', 'NNP', 'O']\n",
      "1344         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "1345         O         O        2 ['4O8', '4o8', 'NN', 'O']\n",
      "1346         O         O        3 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      "\n",
      " 280         O         O       -3 [',', ',', ',', 'O']\n",
      " 281         O         O       -2 ['USA', 'USA', 'NNP', 'O']\n",
      " 282         O         O       -1 [',', ',', ',', 'O']\n",
      " 283         O B-Element    <ERR> ['13Oregon', '13Oregon', 'NNP', 'O']\n",
      " 284         O         O        1 ['State', 'State', 'NNP', 'O']\n",
      " 285         O         O        2 ['University', 'University', 'NNP', 'O']\n",
      " 286         O         O        3 [',', ',', ',', 'O']\n",
      "\n",
      " 286         O         O       -3 [',', ',', ',', 'O']\n",
      " 287         O         O       -2 ['Corvallis', 'Corvallis', 'NNP', 'O']\n",
      " 288         O         O       -1 [',', ',', ',', 'O']\n",
      " 289         O B-Element    <ERR> ['Oregon', 'Oregon', 'NNP', 'O']\n",
      " 290         O         O        1 [',', ',', ',', 'O']\n",
      " 291         O         O        2 ['USA', 'USA', 'NNP', 'O']\n",
      " 292         O         O        3 [',', ',', ',', 'O']\n",
      "\n",
      " 716         O         O       -3 ['interpreted', 'interpret', 'VBN', 'O']\n",
      " 717         O         O       -2 ['at', 'at', 'IN', 'O']\n",
      " 718         O         O       -1 ['the', 'the', 'DT', 'O']\n",
      " 719         O B-Element    <ERR> ['Bradbury', 'Bradbury', 'NNP', 'O']\n",
      " 720         O         O        1 ['landing', 'landing', 'NN', 'O']\n",
      " 721         O         O        2 ['site', 'site', 'NN', 'O']\n",
      " 722         O         O        3 ['-LSB-', '-lsb-', '-LRB-', 'O']\n",
      "\n",
      "  78         O         O       -3 ['2U', '2u', 'NN', 'O']\n",
      "  79         O         O       -2 ['.', '.', '.', 'O']\n",
      "  80         O         O       -1 ['|', '|', '|', 'O']\n",
      "  81         O B-Element    <ERR> ['Copenhagen', 'Copenhagen', 'NNP', 'O']\n",
      "  82         O         O        1 [',', ',', ',', 'O']\n",
      "  83         O         O        2 ['3CalTech', '3CalTech', 'NNP', 'O']\n",
      "  84         O         O        3 [',', ',', ',', 'O']\n",
      "\n",
      " 205         O         O       -3 ['to', 'to', 'TO', 'O']\n",
      " 206         O         O       -2 ['estimate', 'estimate', 'VB', 'O']\n",
      " 207         O         O       -1 ['the', 'the', 'DT', 'O']\n",
      " 208         O B-Element    <ERR> ['halogen', 'halogen', 'NN', 'O']\n",
      " 209         O         O        1 ['budget', 'budget', 'NN', 'O']\n",
      " 210         O         O        2 ['of', 'of', 'IN', 'O']\n",
      " 211         O         O        3 ['Mars', 'Mars', 'NNP', 'O']\n",
      "\n",
      " 780         O         O       -3 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      " 781         O         O       -2 ['F', 'f', 'NN', 'O']\n",
      " 782         O         O       -1 [',', ',', ',', 'O']\n",
      " 783         O B-Element    <ERR> ['Cl', 'cl', 'NN', 'O']\n",
      " 784         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      " 785         O         O        2 ['2', '2', 'CD', 'O']\n",
      " 786         O         O        3 ['Ca10', 'ca10', 'NN', 'O']\n",
      "\n",
      " 791         O         O       -3 ['-LRB-', '-lrb-', '-LRB-', 'O']\n",
      " 792         O         O       -2 ['F', 'f', 'NN', 'O']\n",
      " 793         O         O       -1 [',', ',', ',', 'O']\n",
      " 794         O B-Element    <ERR> ['Cl', 'cl', 'NN', 'O']\n",
      " 795         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      " 796         O         O        2 ['2', '2', 'CD', 'O']\n",
      " 797         O         O        3 ['These', 'these', 'DT', 'O']\n",
      "\n",
      " 866         O         O       -3 ['of', 'of', 'IN', 'O']\n",
      " 867 B-Element B-Element       -2 ['F', 'f', 'NN', 'B-Element']\n",
      " 868         O         O       -1 ['and', 'and', 'CC', 'O']\n",
      " 869         O B-Element    <ERR> ['Cl', 'cl', 'NN', 'O']\n",
      " 870         O         O        1 ['-RRB-', '-rrb-', '-RRB-', 'O']\n",
      " 871         O         O        2 ['.', '.', '.', 'O']\n",
      " 872         O         O        3 ['|', '|', '|', 'O']\n",
      "\n",
      "1330         O         O       -3 ['Spectrochimica', 'Spectrochimica', 'NNP', 'O']\n",
      "1331         O         O       -2 ['Acta', 'Acta', 'NNP', 'O']\n",
      "1332         O         O       -1 ['Part', 'Part', 'NNP', 'O']\n",
      "1333         O B-Element    <ERR> ['B', 'B', 'NNP', 'O']\n",
      "1334         O         O        1 [':', ':', ':', 'O']\n",
      "1335         O         O        2 ['Atomic', 'atomic', 'JJ', 'O']\n",
      "1336         O         O        3 ['Spectroscopy', 'spectroscopy', 'NN', 'O']\n",
      "\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open(model_file)\n",
    "\n",
    "with open(dev_corpus_file, 'rb') as f:\n",
    "    dev_corpus = pickle.load(f)\n",
    "\n",
    "ctx = (-3, 4)\n",
    "c = 0\n",
    "print(\"idx, Truth, Predicted, Word, Comment \")\n",
    "for doc in dev_corpus:\n",
    "    seq = merge_sequences(doc)\n",
    "    y = seq2labels(seq)\n",
    "    y_ = tagger.tag(seq2features(seq))\n",
    "    \n",
    "    for idx in range(len(seq)):\n",
    "        a, p, tok = y[idx], y_[idx], seq[idx]\n",
    "        if a == 'O' and p == 'B-Element':\n",
    "            for pos in filter(lambda p: 0 <= p < len(seq), range(idx+ctx[0], idx+ctx[1])):\n",
    "                if idx == pos:\n",
    "                    label = \"<CORR>\" if a == p else \"<ERR>\"\n",
    "                else:\n",
    "                    label = \"%d\" % (pos - idx)\n",
    "                print(\"%4d %9s %9s %8s %s\" % (pos, y[pos], y_[pos], label, str(seq[pos])))\n",
    "            print(\"\")\n",
    "            if a != p:\n",
    "                c += 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluate\n",
    "\n",
    "### Interpretation of matrix\n",
    "Row sum is total true labels\n",
    "Column sum is predictions total labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set\n",
      "***,B-Mineral,I-Mineral,B-Target,I-Target,B-Element,I-Element,O,total\n",
      "B-Mineral,0,312,0,0,0,0,0,312\n",
      "I-Mineral,0,3,0,0,0,0,0,3\n",
      "B-Target,0,194,0,0,0,0,0,194\n",
      "I-Target,0,20,0,0,0,0,0,20\n",
      "B-Element,0,458,0,0,0,0,0,458\n",
      "I-Element,0,0,0,0,0,0,0,0\n",
      "Precision,0,0.0000,0,0,0,0,0,0\n",
      "Recall,0.0000,1.0000,0.0000,0.0000,0.0000,0,0,0\n",
      "\n",
      "O,0,59643,0,0,0,0,0,59643\n",
      "total,0,60630,0,0,0,0,0,60630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "test_corpus_file = 'mte-corpus-test.pickle'\n",
    "printtable(*evaluate(tagger, test_corpus_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  B-Element       0.85      0.80      0.82       375\n",
      "  B-Mineral       0.80      0.46      0.59       240\n",
      "   B-Target       0.85      0.16      0.26       147\n",
      "   I-Target       0.83      0.36      0.50        14\n",
      "\n",
      "avg / total       0.99      0.99      0.99     34970\n",
      "\n",
      "Testing\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  B-Element       0.87      0.86      0.86       458\n",
      "  B-Mineral       0.76      0.54      0.64       312\n",
      "  I-Mineral       0.00      0.00      0.00         3\n",
      "   B-Target       0.93      0.21      0.34       194\n",
      "   I-Target       0.78      0.35      0.48        20\n",
      "\n",
      "avg / total       0.84      0.62      0.68       987\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    #tagset.append('O')\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )\n",
    "\n",
    "def evaluate(tagger, corpus_file):    \n",
    "    corpus = pickle.load(open(corpus_file, 'rb'))\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for doc in corpus:\n",
    "        seq = merge_sequences(doc)\n",
    "        y_true.append(seq2labels(seq))\n",
    "        y_pred.append(tagger.tag(seq2features(seq)))\n",
    "    return bio_classification_report(y_true, y_pred)\n",
    "\n",
    "\n",
    "dev_corpus_file = 'mte-corpus-dev.pickle'\n",
    "test_corpus_file = 'mte-corpus-test.pickle'\n",
    "print(\"Development\")\n",
    "print(evaluate(tagger, dev_corpus_file))\n",
    "\n",
    "print(\"Testing\")\n",
    "print(evaluate(tagger, test_corpus_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning: State Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "I-Mineral -> I-Mineral 2.129596\n",
      "B-Target -> B-Target 1.777868\n",
      "B-Mineral -> I-Mineral 1.428542\n",
      "I-Target -> B-Target 1.368644\n",
      "O      -> O       1.212534\n",
      "B-Target -> I-Target 0.882359\n",
      "B-Element -> I-Element 0.794664\n",
      "B-Element -> O       0.369301\n",
      "I-Target -> O       0.266107\n",
      "O      -> B-Mineral 0.141097\n",
      "B-Mineral -> O       0.108069\n",
      "I-Target -> I-Target 0.093343\n",
      "O      -> B-Element 0.051150\n",
      "B-Mineral -> B-Mineral 0.022066\n",
      "I-Mineral -> I-Target -0.000002\n",
      "\n",
      "Top unlikely transitions:\n",
      "B-Element -> B-Mineral -0.465545\n",
      "I-Mineral -> O       -0.540627\n",
      "B-Target -> O       -0.609855\n",
      "B-Target -> B-Mineral -0.885765\n",
      "I-Element -> O       -0.937717\n",
      "I-Target -> B-Element -1.059350\n",
      "B-Mineral -> B-Element -1.155835\n",
      "B-Mineral -> B-Target -1.528036\n",
      "O      -> I-Element -1.538932\n",
      "I-Target -> B-Mineral -1.721456\n",
      "B-Target -> B-Element -2.331641\n",
      "B-Mineral -> I-Target -3.745535\n",
      "B-Element -> I-Target -4.946160\n",
      "O      -> I-Mineral -6.515247\n",
      "O      -> I-Target -10.221080\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "info = tagger.info()\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common(15))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common()[-15:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning: State Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "9.980226 B-Element word[-3:]=Pb\n",
      "8.720543 B-Element word[-3:]=Lu\n",
      "7.536495 B-Element word[-3:]=Os\n",
      "7.352061 B-Element word[-3:]=Hf\n",
      "6.097511 B-Element word[-3:]=Rb\n",
      "5.783672 B-Element word[-3:]=Ti\n",
      "5.769140 B-Element word[-3:]=Mo\n",
      "5.766703 B-Element word[-3:]=Al\n",
      "5.668637 B-Element word[-3:]=Fm.\n",
      "5.547315 O      word.pos=DT\n",
      "5.359260 B-Element word[-3:]=Sr\n",
      "5.344576 B-Element word[-3:]=Be\n",
      "5.074022 B-Element word[-3:]=Dy\n",
      "5.074022 B-Element word[-2:]=Dy\n",
      "4.862432 B-Element word[-3:]=ury\n",
      "4.855026 B-Element word[-3:]=Ho\n",
      "4.855026 B-Element word[-2:]=Ho\n",
      "4.853854 B-Element word[-2:]=Sn\n",
      "4.853854 B-Element word[-3:]=Sn\n",
      "4.848583 B-Element word[-2:]=Ge\n",
      "\n",
      "Top negative:\n",
      "-2.769629 O      word[-3:]=Te\n",
      "-2.774340 O      word[-3:]=gen\n",
      "-2.785152 O      word[-3:]=Ca\n",
      "-2.841859 O      word[-3:]=Si\n",
      "-2.865112 O      word[-3:]=Pa\n",
      "-2.915009 O      word[-3:]=cas\n",
      "-3.057446 O      word[-3:]=Li\n",
      "-3.107400 O      word[-3:]=He\n",
      "-3.116127 O      word[-3:]=Sr\n",
      "-3.128704 O      word[-3:]=par\n",
      "-3.222781 O      -1:word[-3:]=-Na\n",
      "-3.265214 O      +2:word[-2:]=pi\n",
      "-3.336028 O      word[-3:]=Ir\n",
      "-3.435297 O      word[-3:]=bon\n",
      "-3.592733 O      word[-3:]=Hg\n",
      "-3.610669 O      word[-3:]=Sm\n",
      "-3.723723 O      word[-3:]=La\n",
      "-3.979239 O      word[-3:]=fur\n",
      "-4.239508 O      word[-3:]=kel\n",
      "-4.525922 B-Element +1:word.pos=POS\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-6s %s\" % (weight, label, attr))    \n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(info.state_features).most_common(20))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(info.state_features).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cvccv ccvc vc ccvccv, cvccv, '"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cvcvc N N'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "s = \"hellow 124.45 -65.7623\"\n",
    "get_wordshape_sound_case(\"hellow 124.45 -65.7623\")\n",
    "#get_wordshape_sound(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ab'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"abcd\"[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
